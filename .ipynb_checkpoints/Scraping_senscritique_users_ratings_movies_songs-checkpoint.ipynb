{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aaf5aca6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-30T16:23:43.058956Z",
     "start_time": "2022-07-30T16:23:43.056089Z"
    }
   },
   "source": [
    "# Scraping senscritique.com: movie and music."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d660c136",
   "metadata": {},
   "source": [
    "In this notebook, we code a scrapper that allows you to generate a dataset containing the preferences of senscritique.com's users in terms of movies and songs. The dataset that is constructed is a dictionnary, for which a keys is an username and a value is a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "703cd87f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-24T10:29:28.996113Z",
     "start_time": "2022-08-24T10:29:28.220830Z"
    }
   },
   "outputs": [],
   "source": [
    "# All of the librairies we require\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import requests\n",
    "from requests import Session\n",
    "from bs4 import BeautifulSoup\n",
    "from lxml import html\n",
    "import time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a13aef4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-24T10:29:30.433213Z",
     "start_time": "2022-08-24T10:29:30.397728Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>users</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/Chlo%C3%A9Pzk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/Electra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/Fanny__Boutonn%C3%A9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/mikmikmik</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/Ondine26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47405</th>\n",
       "      <td>/papa53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47406</th>\n",
       "      <td>/GregBodaway</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47407</th>\n",
       "      <td>/Adrien_Plaine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47408</th>\n",
       "      <td>/Tib%C3%A8reDebout%C3%A9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47409</th>\n",
       "      <td>/raphynette</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>47410 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          users\n",
       "0                /Chlo%C3%A9Pzk\n",
       "1                      /Electra\n",
       "2         /Fanny__Boutonn%C3%A9\n",
       "3                    /mikmikmik\n",
       "4                     /Ondine26\n",
       "...                         ...\n",
       "47405                   /papa53\n",
       "47406              /GregBodaway\n",
       "47407            /Adrien_Plaine\n",
       "47408  /Tib%C3%A8reDebout%C3%A9\n",
       "47409               /raphynette\n",
       "\n",
       "[47410 rows x 1 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# The list of all users on Senscritique.com\n",
    "# This was also obtained by using a scrapping procedure, but it is not hard to reproduce by yourself.\n",
    "with open('url_users_senscritique.txt', 'r') as f:\n",
    "    users = [line.strip() for line in f].copy()\n",
    "\n",
    "users_df = pd.DataFrame(users, columns = ['users'])\n",
    "display(users_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c45807ae",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-08-24T10:36:03.055659Z",
     "start_time": "2022-08-24T10:36:03.052241Z"
    }
   },
   "outputs": [],
   "source": [
    "# Some functions we will need during the computation of the entries\n",
    "\n",
    "def parser_rating(rate):\n",
    "    if rate in {'','-',' '}:\n",
    "        return np.nan\n",
    "    return float(rate)\n",
    "\n",
    "def parser_year(rate):\n",
    "    if rate in {'','-',' '}:\n",
    "        return np.nan\n",
    "    return int(rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fd05497a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-07-30T16:32:51.404113Z",
     "start_time": "2022-07-30T16:32:50.407043Z"
    }
   },
   "outputs": [],
   "source": [
    "# SCRAPPING EVERY RATINGS OF EVERY USER ON SENSCRITIQUE WITH AT LEAST ONE MOVIE AND ONE SONG REVIEW\n",
    "\n",
    "# Before scrapping, we need to log in. Otherwise, you cannot see people's profile set on 'private'.\n",
    "# It is necessary to create an account in order to run this code, as most people's profile will not show up otherwise\n",
    "# Once you have created an account, log in through your web-browser and use the inspector to obtain the cookies and head information.\n",
    "#Also update the cookies information via inspection of the login page, if you do so.\n",
    "# I kept the structure of the dictionnary so that you can reproduce the code, but I removed my own informations\n",
    "cookies = {\n",
    "    'SC_DEVICE_CATEGORY': '',\n",
    "    'SC_SESSIONS_ID': '',\n",
    "    'blocksPush': '',\n",
    "    'SC_SHOW_MODAL_LOGIN': '',\n",
    "    'SC_ID_TOKEN': '',\n",
    "    'SC_REFRESH_TOKEN': '',\n",
    "    'SC_AUTH': '',\n",
    "    'SC_AUTH_UID': '',\n",
    "}\n",
    "\n",
    "headers = {\n",
    "    'User-Agent': '',\n",
    "    'Accept': '',\n",
    "    'Accept-Language': '',\n",
    "    'Accept-Encoding': '',\n",
    "    'Referer': '',\n",
    "    'DNT': '',\n",
    "    'Connection': '',\n",
    "    'Upgrade-Insecure-Requests': '',\n",
    "    'Sec-Fetch-Dest': '',\n",
    "    'Sec-Fetch-Mode': '',\n",
    "    'Sec-Fetch-Site': '',\n",
    "    'Sec-Fetch-User': '',\n",
    "}\n",
    "\n",
    "login_url='https://www.senscritique.com/auth/login'\n",
    "\n",
    "with Session() as c:\n",
    "    c.post(login_url)\n",
    "    \n",
    "    # The object we build has the following type:\n",
    "    # A dictionnary, where the keys are the usernames and the values a three element list.\n",
    "    # Each element of the list is a dataframe: One for movie reviews of the aformentioned user, one for music tracks, one for albums.\n",
    "    # A treatment will probably be applied to merge albums and tracks. I have not decided yet how.\n",
    "    dico_users = dict()\n",
    "\n",
    "    for user in ['auth']:\n",
    "  \n",
    "       #In this block, we check whether the user has both music and movies reviews: otherwise just drop them.\n",
    "        time.sleep(0.01)\n",
    "        profile = c.get('https://www.senscritique.com/'+user, headers=headers, cookies=cookies)\n",
    "        time.sleep(0.01)\n",
    "        html_soup = BeautifulSoup(profile.text, 'html.parser')\n",
    "        data_center_html_soup = html_soup.find_all('div',class_='uvi-stats-pies')\n",
    "        if data_center_html_soup != []:\n",
    "            data_center_html = html_soup.find_all('div',class_='uvi-stats-pies')[0].find_all('a', class_=\"uvi-stats-pie\")\n",
    "            n_data_center = len(data_center_html)\n",
    "            data_center = {'movie': 0,'music': 0}\n",
    "            for i in range(n_data_center):\n",
    "                if data_center_html[i]['data-sc-pie-label'] == 'FILMS':\n",
    "                    data_center['movie'] = int(data_center_html[i]['data-sc-pie-value'])\n",
    "                elif data_center_html[i]['data-sc-pie-label'] == 'MUSIQUE':\n",
    "                    data_center['music'] = int(data_center_html[i]['data-sc-pie-value'])\n",
    "            if (data_center['movie'] != 0 and data_center['music'] != 0):\n",
    "            \n",
    "                #We build the movie review dataframe as a dictionnary, that will be converted into a pd.Dataframe at the end.\n",
    "                list_of_dict_user_movies = []\n",
    "                list_of_dict_user_tracks = []\n",
    "                list_of_dict_user_albums = []\n",
    "                dico_users[user] = []\n",
    "            \n",
    "                #Now, let's start scrapping.\n",
    "                time.sleep(0.01)\n",
    "                response_user = c.get('https://www.senscritique.com/'+user+'/collection/all/films/all/all/all/all/all/all/all/page-1', headers=headers, cookies=cookies)\n",
    "                time.sleep(0.01)\n",
    "                html_soup = BeautifulSoup(response_user.text, 'html.parser')\n",
    "\n",
    "            \n",
    "                number_pages_soup = html_soup.find_all('li', class_=\"eipa-page\")\n",
    "            \n",
    "                if number_pages_soup == []:\n",
    "                    time.sleep(0.01)\n",
    "                    response_user = c.get('https://www.senscritique.com/'+user+'/collection/all/films/all/all/all/all/all/all/all/page-1', headers=headers, cookies=cookies)\n",
    "                    time.sleep(0.01)\n",
    "                    html_soup = BeautifulSoup(response_user.text, 'html.parser')\n",
    "                    num_critics_page = int(len(html_soup.find_all('span', class_= 'elrua-useraction-inner only-child')) / 2)\n",
    "        \n",
    "                    class_rating_user_page = html_soup.find_all('span', class_= 'elrua-useraction-inner only-child')\n",
    "                    list_rating_user_page = [parser_rating(class_rating_user_page[2*i+1].text.replace('\\n','').replace('\\t','')) for i in range(num_critics_page)]\n",
    "        \n",
    "                    global_ratings = html_soup.find_all('a',class_='erra-global')\n",
    "                    list_rating_average = [parser_rating(rating.text.replace('\\n','').replace('\\t','')) for rating in global_ratings]\n",
    "                    list_rating_count = [parser_rating(count['title'].replace('Note globale pondÃ©rÃ©e sur :','').replace('avis','')) for count in global_ratings]\n",
    "     \n",
    "                    #I added one more column in order to make the distinction between movies with the same title (there are like 10 'Rocky' for instance)\n",
    "                    misc_html = html_soup.find_all('p', class_ = 'elco-baseline elco-options')\n",
    "                    list_misc = [misc.text.replace('\\n','').replace('\\t','') for misc in misc_html]\n",
    "\n",
    "                    list_title_page = [re.search('\\n(.*)\\n',(html_soup.find_all('h2', class_= 'd-heading2 elco-title')[i].text)).group(1) for i in range(num_critics_page)]\n",
    "\n",
    "                    for i in range(num_critics_page):\n",
    "                        dict_movie = dict()\n",
    "                        dict_movie['Category'] = 'movie'\n",
    "                        dict_movie['title'] = list_title_page[i]\n",
    "                        dict_movie['misc_info'] = list_misc[i]\n",
    "                        dict_movie['user_rating'] = list_rating_user_page[i]\n",
    "                        dict_movie['total_rating_count'] = list_rating_count[i]\n",
    "                        dict_movie['total_rating_average'] = list_rating_average[i]\n",
    "                        list_of_dict_user_movies.append(dict_movie)\n",
    "                    df_user_collection_movies = pd.DataFrame(list_of_dict_user_movies)\n",
    "                    dico_users[user].append(df_user_collection_movies)\n",
    "\n",
    "                else: \n",
    "                    number_pages = int(number_pages_soup[-1].text.replace('.','').replace('\\n',''))\n",
    "\n",
    "                   #We want to grab the following informations (we know the category will be 'movie'):\n",
    "                   #Title, User rating, Number of ratings, average rating and a column with Misc informations to avoid ambiguities\n",
    "                    for i in range(1,number_pages+1):\n",
    "                        time.sleep(0.01)\n",
    "                        response_user = c.get('https://www.senscritique.com/'+user+'/collection/all/films/all/all/all/all/all/all/all/page-'+str(i), headers=headers, cookies=cookies)\n",
    "                        time.sleep(0.01)\n",
    "                        html_soup = BeautifulSoup(response_user.text, 'html.parser')\n",
    "\n",
    "                        num_critics_page = int(len(html_soup.find_all('span', class_= 'elrua-useraction-inner only-child')) / 2)\n",
    "\n",
    "                        class_rating_user_page = html_soup.find_all('span', class_= 'elrua-useraction-inner only-child')\n",
    "                        list_rating_user_page = [parser_rating(class_rating_user_page[2*i+1].text.replace('\\n','').replace('\\t','')) for i in range(num_critics_page)]\n",
    "\n",
    "                        global_ratings = html_soup.find_all('a',class_='erra-global')\n",
    "                        list_rating_average = [parser_rating(rating.text.replace('\\n','').replace('\\t','')) for rating in global_ratings]\n",
    "                        list_rating_count = [parser_rating(count['title'].replace('Note globale pondÃ©rÃ©e sur :','').replace('avis','')) for count in global_ratings]\n",
    "\n",
    "                        #I added one more column in order to make the distinction between movies with the same title (there are like 10 'Rocky' for instance)\n",
    "                        misc_html = html_soup.find_all('p', class_ = 'elco-baseline elco-options')\n",
    "                        list_misc = [misc.text.replace('\\n','').replace('\\t','') for misc in misc_html]\n",
    "\n",
    "                        list_title_page = [re.search('\\n(.*)\\n',(html_soup.find_all('h2', class_= 'd-heading2 elco-title')[i].text)).group(1) for i in range(num_critics_page)]\n",
    "\n",
    "                        for i in range(num_critics_page):\n",
    "                                dict_movie = dict()\n",
    "                                dict_movie['Category'] = 'movie'\n",
    "                                dict_movie['title'] = list_title_page[i]\n",
    "                                dict_movie['misc_info'] = list_misc[i]\n",
    "                                dict_movie['user_rating'] = list_rating_user_page[i]\n",
    "                                dict_movie['total_rating_count'] = list_rating_count[i]\n",
    "                                dict_movie['total_rating_average'] = list_rating_average[i]\n",
    "                                list_of_dict_user_movies.append(dict_movie)\n",
    "                    df_user_collection_movies = pd.DataFrame(list_of_dict_user_movies)\n",
    "                    dico_users[user].append(df_user_collection_movies)\n",
    "\n",
    "\n",
    "                \n",
    "                   #We do the same for music.\n",
    "                time.sleep(0.01)\n",
    "                response_user = c.get('https://www.senscritique.com/'+user+'/collection/all/morceaux/all/all/all/all/all/all/list/page-1', headers=headers, cookies=cookies)\n",
    "                time.sleep(0.01)\n",
    "                html_soup = BeautifulSoup(response_user.text, 'html.parser')\n",
    "\n",
    "                number_pages_soup = html_soup.find_all('li', class_=\"eipa-page\")#[-1].text.replace('.','').replace('\\n','')\n",
    "                if number_pages_soup == []:\n",
    "                    #number_pages = int(html_soup.find_all('li', class_=\"eipa-page\")[-1].text.replace('.','').replace('\\n',''))\n",
    "\n",
    "                    #We want to grab the following informations (we know the category will be 'movie'):\n",
    "                    #Title, User rating, Number of ratings, average rating and a column with Misc informations to avoid ambiguities\n",
    "                    time.sleep(0.01)\n",
    "                    response_user = c.get('https://www.senscritique.com/'+user+'/collection/all/morceaux/all/all/all/all/all/all/list/page-1', headers=headers, cookies=cookies)\n",
    "                    time.sleep(0.01)\n",
    "                    html_soup = BeautifulSoup(response_user.text, 'html.parser')\n",
    "\n",
    "                    num_critics_page = int(len(html_soup.find_all('span', class_= 'elrua-useraction-inner only-child')) / 2)\n",
    "\n",
    "                    class_rating_user_page = html_soup.find_all('span', class_= 'elrua-useraction-inner only-child')\n",
    "                    list_rating_user_page = [parser_rating(class_rating_user_page[2*i+1].text.replace('\\n','').replace('\\t','')) for i in range(num_critics_page)]\n",
    "\n",
    "                    global_ratings = html_soup.find_all('a',class_='erra-global')\n",
    "                    list_rating_average = [parser_rating(rating.text.replace('\\n','').replace('\\t','')) for rating in global_ratings]\n",
    "                    list_rating_count = [parser_rating(count['title'].replace('Note globale pondÃ©rÃ©e sur :','').replace('avis','')) for count in global_ratings]\n",
    "\n",
    "                    #I added one more column in order to make the distinction between movies with the same title (there are like 10 'Rocky' for instance)\n",
    "                    misc_html = html_soup.find_all('p', class_ = 'elco-baseline elco-options')\n",
    "                    list_misc = [misc.text.replace('\\n','').replace('\\t','') for misc in misc_html]\n",
    "\n",
    "                    list_title_page = [re.search('\\n(.*)\\n',(html_soup.find_all('h2', class_= 'd-heading2 elco-title')[i].text)).group(1) for i in range(num_critics_page)]\n",
    "\n",
    "                    for i in range(num_critics_page):\n",
    "                        dict_tracks = dict()\n",
    "                        dict_tracks['Category'] = 'tracks'\n",
    "                        dict_tracks['title'] = list_title_page[i]\n",
    "                        dict_tracks['misc_info'] = list_misc[i]\n",
    "                        dict_tracks['user_rating'] = list_rating_user_page[i]\n",
    "                        dict_tracks['total_rating_count'] = list_rating_count[i]\n",
    "                        dict_tracks['total_rating_average'] = list_rating_average[i]\n",
    "                        list_of_dict_user_tracks.append(dict_tracks)\n",
    "                    df_user_collection_tracks = pd.DataFrame(list_of_dict_user_tracks) \n",
    "                    dico_users[user].append(df_user_collection_tracks)\n",
    "\n",
    "                else:\n",
    "                    number_pages = int(number_pages_soup[-1].text.replace('.','').replace('\\n',''))\n",
    "\n",
    "               #We want to grab the following informations (we know the category will be 'movie'):\n",
    "               #Title, User rating, Number of ratings, average rating and a column with Misc informations to avoid ambiguities\n",
    "                    for i in range(1,number_pages+1):\n",
    "                        time.sleep(0.01)\n",
    "                        response_user = c.get('https://www.senscritique.com/'+user+'/collection/all/morceaux/all/all/all/all/all/all/list/page-'+str(i), headers=headers, cookies=cookies)\n",
    "                        time.sleep(0.01)\n",
    "                        html_soup = BeautifulSoup(response_user.text, 'html.parser')\n",
    "\n",
    "                        num_critics_page = int(len(html_soup.find_all('span', class_= 'elrua-useraction-inner only-child')) / 2)\n",
    "\n",
    "                        class_rating_user_page = html_soup.find_all('span', class_= 'elrua-useraction-inner only-child')\n",
    "                        list_rating_user_page = [parser_rating(class_rating_user_page[2*i+1].text.replace('\\n','').replace('\\t','')) for i in range(num_critics_page)]\n",
    "\n",
    "                        global_ratings = html_soup.find_all('a',class_='erra-global')\n",
    "                        list_rating_average = [parser_rating(rating.text.replace('\\n','').replace('\\t','')) for rating in global_ratings]\n",
    "                        list_rating_count = [parser_rating(count['title'].replace('Note globale pondÃ©rÃ©e sur :','').replace('avis','')) for count in global_ratings]\n",
    "\n",
    "                        #I added one more column in order to make the distinction between movies with the same title (there are like 10 'Rocky' for instance)\n",
    "                        misc_html = html_soup.find_all('p', class_ = 'elco-baseline elco-options')\n",
    "                        list_misc = [misc.text.replace('\\n','').replace('\\t','') for misc in misc_html]\n",
    "\n",
    "                        list_title_page = [re.search('\\n(.*)\\n',(html_soup.find_all('h2', class_= 'd-heading2 elco-title')[i].text)).group(1) for i in range(num_critics_page)]\n",
    "\n",
    "                        for i in range(num_critics_page):\n",
    "                            dict_tracks = dict()\n",
    "                            dict_tracks['Category'] = 'tracks'\n",
    "                            dict_tracks['title'] = list_title_page[i]\n",
    "                            dict_tracks['misc_info'] = list_misc[i]\n",
    "                            dict_tracks['user_rating'] = list_rating_user_page[i]\n",
    "                            dict_tracks['total_rating_count'] = list_rating_count[i]\n",
    "                            dict_tracks['total_rating_average'] = list_rating_average[i]\n",
    "                            list_of_dict_user_tracks.append(dict_tracks)\n",
    "                    df_user_collection_tracks = pd.DataFrame(list_of_dict_user_tracks) \n",
    "                    dico_users[user].append(df_user_collection_tracks)\n",
    "\n",
    "                #We do the same for albums.\n",
    "                time.sleep(0.01)\n",
    "                response_user = c.get('https://www.senscritique.com/'+user+'/collection/all/albums/all/all/all/all/all/all/list/page-1', headers=headers, cookies=cookies)\n",
    "                time.sleep(0.01)\n",
    "                html_soup = BeautifulSoup(response_user.text, 'html.parser')\n",
    "\n",
    "                number_pages_soup = html_soup.find_all('li', class_=\"eipa-page\")#[-1].text.replace('.','').replace('\\n','')\n",
    "                if number_pages_soup == []:\n",
    "                    #number_pages = int(html_soup.find_all('li', class_=\"eipa-page\")[-1].text.replace('.','').replace('\\n',''))\n",
    "\n",
    "                    #We want to grab the following informations (we know the category will be 'movie'):\n",
    "                    #Title, User rating, Number of ratings, average rating and a column with Misc informations to avoid ambiguities\n",
    "                    time.sleep(0.01)\n",
    "                    response_user = c.get('https://www.senscritique.com/'+user+'/collection/all/albums/all/all/all/all/all/all/list/page-1', headers=headers, cookies=cookies)\n",
    "                    time.sleep(0.01)\n",
    "                    html_soup = BeautifulSoup(response_user.text, 'html.parser')\n",
    "\n",
    "                    num_critics_page = int(len(html_soup.find_all('span', class_= 'elrua-useraction-inner only-child')) / 2)\n",
    "\n",
    "                    class_rating_user_page = html_soup.find_all('span', class_= 'elrua-useraction-inner only-child')\n",
    "                    list_rating_user_page = [parser_rating(class_rating_user_page[2*i+1].text.replace('\\n','').replace('\\t','')) for i in range(num_critics_page)]\n",
    "\n",
    "                    global_ratings = html_soup.find_all('a',class_='erra-global')\n",
    "                    list_rating_average = [parser_rating(rating.text.replace('\\n','').replace('\\t','')) for rating in global_ratings]\n",
    "                    list_rating_count = [parser_rating(count['title'].replace('Note globale pondÃ©rÃ©e sur :','').replace('avis','')) for count in global_ratings]\n",
    "\n",
    "                    #I added one more column in order to make the distinction between movies with the same title (there are like 10 'Rocky' for instance)\n",
    "                    misc_html = html_soup.find_all('p', class_ = 'elco-baseline elco-options')\n",
    "                    list_misc = [misc.text.replace('\\n','').replace('\\t','') for misc in misc_html]\n",
    "\n",
    "                    list_title_page = [re.search('\\n(.*)\\n',(html_soup.find_all('h2', class_= 'd-heading2 elco-title')[i].text)).group(1) for i in range(num_critics_page)]\n",
    "\n",
    "                    for i in range(num_critics_page):\n",
    "                        dict_albums = dict()\n",
    "                        dict_albums['Category'] = 'albums'\n",
    "                        dict_albums['title'] = list_title_page[i]\n",
    "                        dict_albums['misc_info'] = list_misc[i]\n",
    "                        dict_albums['user_rating'] = list_rating_user_page[i]\n",
    "                        dict_albums['total_rating_count'] = list_rating_count[i]\n",
    "                        dict_albums['total_rating_average'] = list_rating_average[i]\n",
    "                        list_of_dict_user_albums.append(dict_albums)\n",
    "                    df_user_collection_albums = pd.DataFrame(list_of_dict_user_albums) \n",
    "                    dico_users[user].append(df_user_collection_albums)\n",
    "\n",
    "                else:\n",
    "                    number_pages = int(number_pages_soup[-1].text.replace('.','').replace('\\n',''))\n",
    "\n",
    "               #We want to grab the following informations (we know the category will be 'movie'):\n",
    "               #Title, User rating, Number of ratings, average rating and a column with Misc informations to avoid ambiguities\n",
    "                    for i in range(1,number_pages+1):\n",
    "                        time.sleep(0.01)\n",
    "                        response_user = c.get('https://www.senscritique.com/'+user+'/collection/all/albums/all/all/all/all/all/all/list/page-'+str(i), headers=headers, cookies=cookies)\n",
    "                        time.sleep(0.01)\n",
    "                        html_soup = BeautifulSoup(response_user.text, 'html.parser')\n",
    "\n",
    "                        num_critics_page = int(len(html_soup.find_all('span', class_= 'elrua-useraction-inner only-child')) / 2)\n",
    "\n",
    "                        class_rating_user_page = html_soup.find_all('span', class_= 'elrua-useraction-inner only-child')\n",
    "                        list_rating_user_page = [parser_rating(class_rating_user_page[2*i+1].text.replace('\\n','').replace('\\t','')) for i in range(num_critics_page)]\n",
    "\n",
    "                        global_ratings = html_soup.find_all('a',class_='erra-global')\n",
    "                        list_rating_average = [parser_rating(rating.text.replace('\\n','').replace('\\t','')) for rating in global_ratings]\n",
    "                        list_rating_count = [parser_rating(count['title'].replace('Note globale pondÃ©rÃ©e sur :','').replace('avis','')) for count in global_ratings]\n",
    "\n",
    "                        #I added one more column in order to make the distinction between movies with the same title (there are like 10 'Rocky' for instance)\n",
    "                        misc_html = html_soup.find_all('p', class_ = 'elco-baseline elco-options')\n",
    "                        list_misc = [misc.text.replace('\\n','').replace('\\t','') for misc in misc_html]\n",
    "\n",
    "                        list_title_page = [re.search('\\n(.*)\\n',(html_soup.find_all('h2', class_= 'd-heading2 elco-title')[i].text)).group(1) for i in range(num_critics_page)]\n",
    "\n",
    "                        for i in range(num_critics_page):\n",
    "                            dict_albums = dict()\n",
    "                            dict_albums['Category'] = 'albums'\n",
    "                            dict_albums['title'] = list_title_page[i]\n",
    "                            dict_albums['misc_info'] = list_misc[i]\n",
    "                            dict_albums['user_rating'] = list_rating_user_page[i]\n",
    "                            dict_albums['total_rating_count'] = list_rating_count[i]\n",
    "                            dict_albums['total_rating_average'] = list_rating_average[i]\n",
    "                            list_of_dict_user_albums.append(dict_albums)\n",
    "                    df_user_collection_albums = pd.DataFrame(list_of_dict_user_albums) \n",
    "                    dico_users[user].append(df_user_collection_albums)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": true,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
